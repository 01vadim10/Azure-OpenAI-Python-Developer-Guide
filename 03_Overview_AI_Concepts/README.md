# Overview of the following concepts (summaries with reference links):


## Large Language Models (LLM)

## Standard Patterns

### RAG

Retrieval Augmentation Generation (RAG) is an architecture that augments the capabilities of a Large Language Model (LLM) like ChatGPT by adding an information retrieval system that provides grounding data. Adding an information retrieval system gives you control over grounding data used by an LLM when it formulates a response. For an enterprise solution, RAG architecture means that you can constrain generative AI to your enterprise content sourced from vectorized documents, images, audio, and video.

https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview

### CoT

Instead of splitting a task into smaller steps, with Chain of Though (CoT) the model response is instructed to proceed step-by-step and present all the steps involved. Doing so reduces the possibility of inaccuracy of outcomes and makes assessing the model response easier.

https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#chain-of-thought-prompting

### ReAct

### Others?

https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#provide-grounding-context


## Vectorization and Vector Search

What are you trying to solve with finding relevant data through vector?

## Prompt Engineering

https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering

https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/
